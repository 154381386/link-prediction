{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "import pydot\n",
    "import random as python_random\n",
    "import numpy    \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import coo_matrix\n",
    "from time import gmtime, strftime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.lines as mlines\n",
    "from scipy.sparse import linalg\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_nodes(graph, nodes):\n",
    "    for n in nodes:\n",
    "        if isinstance(n, tuple):\n",
    "            graph.node(n[0], **n[1])\n",
    "        else:\n",
    "            graph.node(n)\n",
    "    return graph\n",
    "\n",
    "def add_edges(graph, edges):\n",
    "    for e in edges:\n",
    "        if isinstance(e[0], tuple):\n",
    "            graph.edge(*e[0], **e[1])\n",
    "        else:\n",
    "            graph.edge(*e)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(u, w, nodes_pos, A=[], H=[]):\n",
    "    nodes_pos_u = nodes_pos[u]\n",
    "    nodes_pos_w = nodes_pos[w]\n",
    "    length = len(nodes_pos_u)\n",
    "    dist = 0.0\n",
    "    for i in range(length):\n",
    "        dist = dist + (nodes_pos_u[i] - nodes_pos_w[i])**2\n",
    "        \n",
    "    return -(dist)**0.5\n",
    "\n",
    "def node2vec_score(u, w, nodes_pos, A=[], H=[]):\n",
    "    nodes_pos_u = nodes_pos[u]\n",
    "    nodes_pos_w = nodes_pos[w]\n",
    "    return numpy.dot(nodes_pos_u, nodes_pos_w)\n",
    "\n",
    "def mf_score(u, w, nodes_pos, A, H):\n",
    "    return numpy.dot(A[int(u)], H.T[int(w)])\n",
    "    \n",
    "def svd_score(u, w, nodes_pos, A, H):\n",
    "    return numpy.dot(A[int(u)], A[int(w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(nodes_pos, pos_set, neg_set, functs, A=[], H=[]):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for edge in pos_set:\n",
    "        u, w = edge\n",
    "        x = []\n",
    "        try:\n",
    "            for func in functs:\n",
    "                x.append(func(u, w, nodes_pos, A, H))\n",
    "        except:\n",
    "            continue\n",
    "        X.append(x)\n",
    "        Y.append(1)\n",
    "        \n",
    "    for edge in neg_set:\n",
    "        u, w = edge\n",
    "        x = []\n",
    "        try:\n",
    "            for func in functs:\n",
    "                x.append(func(u, w, nodes_pos, A, H))\n",
    "        except:\n",
    "            continue\n",
    "        X.append(x)\n",
    "        Y.append(0)\n",
    "        \n",
    "    X = numpy.array(X)\n",
    "    Y = numpy.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sparse_matrix(train_set, n):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for edge in train_set:\n",
    "        u = int(edge[0])\n",
    "        w = int(edge[1])\n",
    "        row.append(u)\n",
    "        col.append(w)\n",
    "        row.append(w)\n",
    "        col.append(u)\n",
    "        data.append(1)\n",
    "        data.append(1)\n",
    "    return coo_matrix((data, (row, col)), shape=(n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_giant_component(nodes, edges):\n",
    "    edges = set(edges)\n",
    "    nodes = list(nodes)\n",
    "    \n",
    "    node2edges = {node : [] for node in nodes}\n",
    "    for edge in edges:\n",
    "        node2edges[edge[0]].append(edge)\n",
    "        node2edges[edge[1]].append(edge)\n",
    "    \n",
    "    def walk(source, visited):\n",
    "        queue = set()\n",
    "        if source not in visited:\n",
    "            queue.add(source)\n",
    "        while len(queue) > 0:\n",
    "            current = queue.pop()\n",
    "            visited.add(current)\n",
    "            for edge in node2edges[current]:\n",
    "                if edge[0] == current:\n",
    "                    added = edge[1]\n",
    "                else:\n",
    "                    added = edge[0]\n",
    "                if added not in visited:\n",
    "                    queue.add(added)\n",
    "    \n",
    "    visited = set()\n",
    "    walk(python_random.choice(nodes), visited)\n",
    "    if len(visited) != len(nodes):\n",
    "        print 'Graph is disconnected, will try to choice giant component'\n",
    "        while len(visited) < 0.5 * len(nodes):\n",
    "            visited = set()\n",
    "            walk(python_random.choice(nodes), visited)\n",
    "        old_edges_count = len(edges)\n",
    "        old_nodes_count = len(nodes)\n",
    "        edges = set([edge for edge in edges if edge[0] in visited and edge[1] in visited])\n",
    "        nodes = set(visited)\n",
    "        print 'Giant component: %d of %d nodes, %d of %d edges' % (len(nodes), old_nodes_count, \n",
    "                                                                   len(edges), old_edges_count)\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_train(dataset_name):\n",
    "    max_id = 0\n",
    "    file_name = dataset_name + \"/train.in\"\n",
    "    fin_train = open(file_name, 'r')\n",
    "    edges = set()\n",
    "    nodes = set()\n",
    "    for line in fin_train:\n",
    "        line = line.strip()\n",
    "        # assume undirected!\n",
    "        u, w = sorted(line.split())\n",
    "        edges.add((u,w))\n",
    "        nodes.add(u)\n",
    "        nodes.add(w)\n",
    "    fin_train.close()\n",
    "\n",
    "    nodes, edges = get_giant_component(nodes, edges)\n",
    "    max_id = max(map(int, nodes))\n",
    "    return edges, nodes, max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample edges while keeping graph connected\n",
    "def safe_sample_edges(nodes, edges, sample_size):   \n",
    "    edges = set(edges)\n",
    "    nodes = list(nodes)\n",
    "    \n",
    "    edge_label = {}\n",
    "    node2edges = {node : [] for node in nodes}\n",
    "    for edge in edges:\n",
    "        node2edges[edge[0]].append(edge)\n",
    "        node2edges[edge[1]].append(edge)\n",
    "        edge_label[edge] = 'keep'\n",
    "    \n",
    "    def walk(source, visited):\n",
    "        queue = set()\n",
    "        if source not in visited:\n",
    "            queue.add(source)\n",
    "        while len(queue) > 0:\n",
    "            current = queue.pop()\n",
    "            visited.add(current)\n",
    "            for edge in node2edges[current]:\n",
    "                if edge_label[edge] == 'keep':\n",
    "                    if edge[0] == current:\n",
    "                        added = edge[1]\n",
    "                    else:\n",
    "                        added = edge[0]\n",
    "                    if added not in visited:\n",
    "                        queue.add(added)\n",
    "           \n",
    "    sampled_edges = set()\n",
    "    iteration = 0\n",
    "    while len(sampled_edges) < sample_size:\n",
    "        candidates = python_random.sample(edges - sampled_edges, sample_size - len(sampled_edges))\n",
    "        for edge in candidates:\n",
    "            edge_label[edge] = 'candidate'\n",
    "        visited = set()\n",
    "        source = python_random.choice(nodes)\n",
    "        while len(visited) < len(nodes):\n",
    "            assert(source not in visited)\n",
    "            walk(source, visited)\n",
    "            for edge in candidates:\n",
    "                if edge_label[edge] == 'candidate':\n",
    "                    if edge[0] not in visited and edge[1] in visited:\n",
    "                        edge_label[edge] = 'keep'\n",
    "                        source = edge[0]\n",
    "                        break\n",
    "                    elif edge[1] not in visited and edge[0] in visited:\n",
    "                        edge_label[edge] = 'keep'\n",
    "                        source = edge[1]\n",
    "                        break\n",
    "                    elif edge[0] in visited and edge[1] in visited:\n",
    "                        edge_label[edge] = 'remove'\n",
    "                    else:\n",
    "                        pass\n",
    "        for edge in edges:\n",
    "            if edge_label[edge] == 'remove':\n",
    "                sampled_edges.add(edge)\n",
    "            assert(edge_label[edge] != 'candidate')\n",
    "        print 'Iteration %d, sampled edges %d' % (iteration, len(sampled_edges))\n",
    "        iteration += 1\n",
    "\n",
    "    return nodes, edges, sampled_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sets(nodes, edges, division=10):\n",
    "    nodes_size = len(nodes)\n",
    "    edges_size = len(edges)\n",
    "    print \"Nodes size: \" + str(nodes_size)\n",
    "    print \"Edges size: \" + str(edges_size)\n",
    "    test_size = int(edges_size * (division / 100.0))\n",
    "        \n",
    "    nodes, edges, pos_edges = safe_sample_edges(nodes, edges, test_size)\n",
    "    pos_edges = set(pos_edges)\n",
    "    neg_edges = set()\n",
    "    while len(neg_edges) < test_size:\n",
    "        u, w = sorted(map(str, list(python_random.sample(nodes, 2))))\n",
    "        edge = (u, w)\n",
    "        if edge not in edges and u != w:\n",
    "            neg_edges.add(edge)\n",
    "        \n",
    "    edges_not_full = edges - pos_edges\n",
    "    print \"Edges not full: \" + str(len(edges_not_full))\n",
    "    \n",
    "    return pos_edges, neg_edges, edges_not_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_graph(dataset_name, dimension, nodes, edges_not_full):\n",
    "    graph = gv.Graph(format=\"dot\")\n",
    "    graph.engine = 'sfdp'\n",
    "    graph.graph_attr['dim'] = str(dimension)\n",
    "    graph.graph_attr['dimen'] = str(dimension)\n",
    "    graph = add_nodes(graph, nodes)\n",
    "    graph = add_edges(graph, edges_not_full)\n",
    "    file_name = dataset_name + \"/sfdp_graph\" #+ str(dimension)\n",
    "    graph.render(file_name, view=False)\n",
    "    \n",
    "    graph.format = \"png\"\n",
    "    graph.render(file_name, view=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_edges_dot(dataset_name, dimension):\n",
    "    file_name = dataset_name + \"/sfdp_graph\" + \".dot\" #+ str(dimension) + \".dot\"\n",
    "    dot_graph = pydot.graph_from_dot_file(file_name)[0]\n",
    "    dot_nodes = dot_graph.get_nodes()\n",
    "    nodes_pos = {}\n",
    "    for node in dot_nodes:\n",
    "        name = node.get_name()\n",
    "        if name != 'node' and name != 'graph':\n",
    "            pos_str = node.get('pos').strip('\"')        \n",
    "            nodes_pos[name] = map(float, pos_str.split(','))\n",
    "    return nodes_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_sfdp(nodes_pos, pos_edges, neg_edges):\n",
    "    X, Y = make_dataset(nodes_pos, pos_edges, neg_edges, [dist])\n",
    "    score = roc_auc_score(Y, X)\n",
    "    print \"SFDP \" + str(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_nmf(edges, pos_edges, neg_edges, n_components, max_id):\n",
    "    G = make_sparse_matrix(edges, max_id + 1)\n",
    "    model = NMF(n_components=n_components, init='random')\n",
    "    W = model.fit_transform(G)\n",
    "    H = model.components_\n",
    "    \n",
    "    X, Y = make_dataset(None, pos_edges, neg_edges, [mf_score], W, H)\n",
    "    \n",
    "    score = roc_auc_score(Y, X)\n",
    "    print \"NMF \" + str(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_svd(edges, pos_edges, neg_edges, n_components, max_id):\n",
    "    G = make_sparse_matrix(edges, max_id + 1)\n",
    "\n",
    "    U, s, Vh = linalg.svds(G.asfptype(), k=n_components)\n",
    "    Us = U * s\n",
    "    \n",
    "    X, Y = make_dataset(None, pos_edges, neg_edges, [mf_score], Us, Vh)\n",
    "    \n",
    "    score = roc_auc_score(Y, X)\n",
    "    print \"SVD \" + str(score)\n",
    "    return score, Us, Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def auc_node2vec(dataset_name, edges, pos_edges, neg_edges, dimension):\n",
    "    node2vec_in = dataset_name + '/' + 'node2vec.in'\n",
    "    node2vec_out = dataset_name + '/' + 'node2vec.out'\n",
    "\n",
    "    fin = open(node2vec_in, 'w')\n",
    "    for edge in edges:\n",
    "        print>>fin, '%s\\t%s' % (edge[0], edge[1])\n",
    "    fin.close()\n",
    "\n",
    "    os.system('python ../node2vec/main.py --input \"%s\" --output \"%s\" '\n",
    "              '--dimensions %d --walk-length 80 --p 1 --iter 1' % (node2vec_in, node2vec_out, dimension))\n",
    "    \n",
    "    fout = open(node2vec_out, 'r')\n",
    "    fout.readline() # skip header   \n",
    "    nodes_pos = {}\n",
    "    for line in fout:\n",
    "        fields = line.split()\n",
    "        nodes_pos[fields[0]] = np.array(map(float, fields[1:]))\n",
    "\n",
    "    X, Y = make_dataset(nodes_pos, pos_edges, neg_edges, [node2vec_score])\n",
    "    score = roc_auc_score(Y, X)\n",
    "    print \"node2vec \" + str(score)\n",
    "    return score, nodes_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mean(dim, nodes_pos):\n",
    "    values = []\n",
    "\n",
    "    for i in range(dim):\n",
    "        values.append([])\n",
    "\n",
    "    for node in nodes_pos:\n",
    "        for i in range(dim):\n",
    "            values[i].append(nodes_pos[node][i])\n",
    "        \n",
    "    for i in range(dim):\n",
    "        print np.mean(values[i])\n",
    "        print np.std(values[i])\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def draw_3d_vectors(dataset_name, vectors, method):\n",
    "    try:\n",
    "        plt.rcParams[\"figure.figsize\"] = [15, 15]\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter3D(vectors[:,0], vectors[:,1], vectors[:,2])\n",
    "        ax.autoscale_view(tight=True)\n",
    "        file_name = dataset_name + \"/3d_%s_as_cloud.png\" % method\n",
    "        fig.savefig(file_name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_graph(dataset_name, nodes_pos, edges):\n",
    "    vectors = []\n",
    "    for node in nodes_pos:\n",
    "        vectors.append(np.array(nodes_pos[node]))\n",
    "    vectors = np.array(vectors)   \n",
    "    draw_3d_vectors(dataset_name, vectors, 'sfdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_graph_node2vec(dataset_name, nodes_pos):\n",
    "    vectors = []\n",
    "    for node in nodes_pos:\n",
    "        vectors.append(np.array(nodes_pos[node]))\n",
    "    vectors = np.array(vectors)   \n",
    "    draw_3d_vectors(dataset_name, vectors, 'node2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_graph_svd(dataset_name, U, V):    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    Vt = np.transpose(V)   \n",
    "    draw_3d_vectors(dataset_name, np.concatenate((U, Vt)), 'svd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dim_exp(dataset_name, num_exps, dimensions, division):\n",
    "    dim_scores_sfdp = {}\n",
    "    dim_scores_nmf = {}\n",
    "    dim_scores_svd = {}\n",
    "    dim_scores_node2vec = {}\n",
    "    for dimension in dimensions:\n",
    "            dim_scores_sfdp[dimension] = np.array([])\n",
    "            dim_scores_nmf[dimension] = np.array([])\n",
    "            dim_scores_svd[dimension] = np.array([])\n",
    "            dim_scores_node2vec[dimension] = np.array([])\n",
    "            \n",
    "    edges, nodes, max_id = read_train(dataset_name)\n",
    "    \n",
    "    for dimension in dimensions:\n",
    "        print \"Dimension \" + str(dimension)\n",
    "        \n",
    "        for i in range(num_exps):\n",
    "            print \"Launch \" + str(i)\n",
    "            print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "            \n",
    "            pos_edges, neg_edges, edges_not_full = get_sets(nodes, edges, division)\n",
    "\n",
    "            node2vec_scores, node2vec_nodes_pos = auc_node2vec(dataset_name, edges_not_full, pos_edges, neg_edges, dimension)\n",
    "            dim_scores_node2vec[dimension] = np.append(dim_scores_node2vec[dimension], node2vec_scores)\n",
    "            \n",
    "            if dimension <= 10:\n",
    "                render_graph(dataset_name, dimension, nodes, edges_not_full)\n",
    "                nodes_pos = read_edges_dot(dataset_name, dimension)            \n",
    "                sfdp_scores = auc_sfdp(nodes_pos, pos_edges, neg_edges)\n",
    "                dim_scores_sfdp[dimension] = np.append(dim_scores_sfdp[dimension], sfdp_scores)\n",
    "    \n",
    "            nmf_scores = auc_nmf(edges_not_full, pos_edges, neg_edges, dimension, max_id)\n",
    "            dim_scores_nmf[dimension] = np.append(dim_scores_nmf[dimension], nmf_scores)\n",
    "    \n",
    "            svd_scores, U, V = auc_svd(edges_not_full, pos_edges, neg_edges, dimension, max_id)\n",
    "            dim_scores_svd[dimension] = np.append(dim_scores_svd[dimension], svd_scores)\n",
    "               \n",
    "            if dimension == 3:\n",
    "                print \"Draw graph\"\n",
    "                draw_graph_node2vec(dataset_name, node2vec_nodes_pos)\n",
    "                draw_graph(dataset_name, nodes_pos, edges)\n",
    "                draw_graph_svd(dataset_name, U, V)\n",
    "            \n",
    "    return dim_scores_sfdp, dim_scores_nmf, dim_scores_svd, dim_scores_node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import median, absolute, mean\n",
    "import numpy as np\n",
    "\n",
    "def mad(data, axis=None):\n",
    "    return median(absolute(data - median(data, axis)), axis)\n",
    "\n",
    "def mad_std(x, axis=None):\n",
    "    return 1.4826 * mad(x, axis)\n",
    "\n",
    "def robust_mean(x):\n",
    "    filtered = int(len(x) * 0.2)\n",
    "    return mean(sorted(x)[filtered:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851666666667\n"
     ]
    }
   ],
   "source": [
    "print robust_mean(np.array([0.8, 0.9, 0.88, 0.83, 0.84, 0.86, -100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_scores(dataset_name, dimensions, ticks,\n",
    "                dim_scores_sfdp, dim_scores_nmf, dim_scores_svd, dim_scores_node2vec, \n",
    "                with_lines, suffix=\"\", show=False, shift=0.15):\n",
    "    plt.rcParams[\"figure.figsize\"] = [6, 4]\n",
    "    scores_sfdp = []\n",
    "    scores_nmf = []\n",
    "    scores_svd = []\n",
    "    scores_node2vec = []\n",
    "    shift = shift\n",
    "    dimensions_sfdp = []\n",
    "    dimensions_nmf = []\n",
    "    dimensions_svd = []\n",
    "    dimensions_node2vec = []\n",
    "    err_sfdp = []\n",
    "    err_nmf = []\n",
    "    err_svd = []\n",
    "    err_node2vec = []\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        if dim not in ticks:\n",
    "            continue\n",
    "        if dim in dim_scores_sfdp:\n",
    "            scores_sfdp.append(robust_mean(dim_scores_sfdp[dim]))\n",
    "        scores_nmf.append(robust_mean(dim_scores_nmf[dim]))\n",
    "        scores_svd.append(robust_mean(dim_scores_svd[dim]))\n",
    "        scores_node2vec.append(robust_mean(dim_scores_node2vec[dim]))\n",
    "        dimensions_sfdp.append(dim - 2 * shift)\n",
    "        dimensions_nmf.append(dim - shift)\n",
    "        dimensions_svd.append(dim + shift)\n",
    "        dimensions_node2vec.append(dim + 2 * shift)\n",
    "        if dim in dim_scores_sfdp:\n",
    "            err_sfdp.append(mad_std(dim_scores_sfdp[dim]) * 2)\n",
    "        err_nmf.append(mad_std(dim_scores_nmf[dim]) * 2)\n",
    "        err_svd.append(mad_std(dim_scores_svd[dim]) * 2)\n",
    "        err_node2vec.append(mad_std(dim_scores_node2vec[dim]) * 2)\n",
    "\n",
    "    print \"sfdp scores\"\n",
    "    print scores_sfdp\n",
    "    print \"nmf scores\"\n",
    "    print scores_nmf\n",
    "    print \"svd scores\"\n",
    "    print scores_svd\n",
    "    print \"node2vec scores\"\n",
    "    print scores_node2vec    \n",
    "    print \"sfdp err\"\n",
    "    print err_sfdp\n",
    "    print \"nmf err\"\n",
    "    print err_nmf\n",
    "    print \"svd err\"\n",
    "    print err_svd\n",
    "    print \"node2vec err\"\n",
    "    print err_node2vec\n",
    "    \n",
    "    fig, ax = plt.subplots( nrows=1, ncols=1 )\n",
    "    \n",
    "    linewidth = 0\n",
    "    if with_lines:\n",
    "        linewidth = 1\n",
    "    \n",
    "    plt.errorbar(x=dimensions_sfdp, y=scores_sfdp, yerr=err_sfdp, c='g', marker='o', linestyle='-', markersize=2, linewidth=linewidth, elinewidth=1)\n",
    "    plt.errorbar(x=dimensions_nmf, y=scores_nmf, yerr=err_nmf,c='r', marker='o', linestyle='-.', markersize=2, linewidth=linewidth, elinewidth=1)\n",
    "    plt.errorbar(x=dimensions_svd, y=scores_svd, yerr=err_svd,c='b', marker='o', linestyle=':', markersize=2, linewidth=linewidth, elinewidth=1)\n",
    "    plt.errorbar(x=dimensions_node2vec, y=scores_node2vec, yerr=err_node2vec,c='magenta', marker='o', linestyle='--', markersize=2, linewidth=linewidth, elinewidth=1)\n",
    "    \n",
    "    plt.xlim([1, max(dimensions) + 1])\n",
    "    plt.ylim(ymax=1.01)\n",
    "    plt.xticks(ticks)\n",
    "\n",
    "    ax.set_xlabel('Dimensionality')\n",
    "    ax.set_ylabel('AUC')\n",
    "    \n",
    "    sfdp = mlines.Line2D([], [], linestyle='-', color='green')\n",
    "    nmf = mlines.Line2D([], [], linestyle='-.', color='red')\n",
    "    svd = mlines.Line2D([], [], linestyle=':', color='blue')\n",
    "    node2vec = mlines.Line2D([], [], linestyle='--', color='magenta')\n",
    "    ax.legend([sfdp, svd, nmf, node2vec], [\"SFDP\", \"SVD\", \"NMF\", \"node2vec\"], fontsize = 'small', loc=4)\n",
    "    fig.suptitle(os.path.basename(dataset_name))\n",
    "    plt.legend()\n",
    "\n",
    "    file_name = \"\"\n",
    "    dataset_name_lower = os.path.basename(dataset_name).replace(' ', '_').lower()\n",
    "    if with_lines:\n",
    "        file_name = dataset_name + \"/\" + dataset_name_lower + \"_dims%s.pdf\" % suffix\n",
    "    else:\n",
    "        file_name = dataset_name + \"/\" + dataset_name_lower + \"_dims%s_no_lines.pdf\" % suffix\n",
    "    fig.savefig(file_name, format='pdf', bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare triangulated sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges count: 7680\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/mikedh/trimesh\n",
    "\n",
    "import trimesh as t\n",
    "import os\n",
    "\n",
    "s = t.primitives.Sphere(subdivisions=4)\n",
    "edges = []\n",
    "for face in s.faces:\n",
    "    edges += [\n",
    "        '\\t'.join(map(str,sorted([face[0], face[1]]))),\n",
    "        '\\t'.join(map(str,sorted([face[1], face[2]]))),\n",
    "        '\\t'.join(map(str,sorted([face[0], face[2]])))\n",
    "    ]\n",
    "\n",
    "edges = list(set(edges))\n",
    "print 'Edges count: %d' % len(edges)\n",
    "\n",
    "if not os.path.exists('../data/3d_sphere_triang'):\n",
    "    os.makedirs('../data/3d_sphere_triang')\n",
    "out = open('../data/3d_sphere_triang/train.in', 'w')\n",
    "for edge in edges:\n",
    "    print>>out, edge\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "\n",
    "dataset_names = [\"../data/3d_sphere_triang\"]\n",
    "ns = [5]\n",
    "fractions = [30]\n",
    "dimensions = [2,3,4,5,6,7,8,9,10,20,30,40,50,75,100]\n",
    "\n",
    "for dataset_name, n, fraction in zip(dataset_names, ns, fractions):\n",
    "    print dataset_name\n",
    "    dim_scores_sfdp, dim_scores_nmf, dim_scores_svd, dim_scores_node2vec = run_dim_exp(dataset_name, n, dimensions, fraction)\n",
    "    print \"saving\"\n",
    "    print dataset_name\n",
    "    save_scores(dataset_name, dimensions[:9], dimensions[:9], dim_scores_sfdp, dim_scores_nmf, dim_scores_svd, dim_scores_node2vec, True, '1', False, shift=0.1)\n",
    "    save_scores(dataset_name, dimensions, [2,10,20,30,40,50,75,100], dim_scores_sfdp, dim_scores_nmf, dim_scores_svd, dim_scores_node2vec, True, '2', False, shift=0.4)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
