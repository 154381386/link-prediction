{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "import pydot\n",
    "import random\n",
    "import numpy    \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from  sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import coo_matrix\n",
    "from time import gmtime, strftime\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_nodes(graph, nodes):\n",
    "    for n in nodes:\n",
    "        if isinstance(n, tuple):\n",
    "            graph.node(n[0], **n[1])\n",
    "        else:\n",
    "            graph.node(n)\n",
    "    return graph\n",
    "\n",
    "def add_edges(graph, edges):\n",
    "    for e in edges:\n",
    "        if isinstance(e[0], tuple):\n",
    "            graph.edge(*e[0], **e[1])\n",
    "        else:\n",
    "            graph.edge(*e)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(u, w, nodes_pos, A=[]):\n",
    "    nodes_pos_u = nodes_pos[u]\n",
    "    nodes_pos_w = nodes_pos[w]\n",
    "    length = len(nodes_pos_u)\n",
    "    dist = 0.0\n",
    "    for i in range(length):\n",
    "        dist = dist + (nodes_pos_u[i] - nodes_pos_w[i])**2\n",
    "        \n",
    "    return (dist)**0.5\n",
    "\n",
    "def mf_score(u, w, nodes_pos, A):\n",
    "    return numpy.dot(A[int(u)], A[int(w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(nodes_pos, pos_set, neg_set, functs, A=[]):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for edge in pos_set:\n",
    "        u, w = edge\n",
    "        x = []\n",
    "        for func in functs:\n",
    "            x.append(func(u, w, nodes_pos, A))\n",
    "        X.append(x)\n",
    "        Y.append(1)\n",
    "        \n",
    "    for edge in neg_set:\n",
    "        u, w = edge\n",
    "        x = []\n",
    "        for func in functs:\n",
    "            x.append(func(u, w, nodes_pos, A))\n",
    "        X.append(x)\n",
    "        Y.append(0)\n",
    "        \n",
    "    X = numpy.array(X)\n",
    "    Y = numpy.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sparse_matrix(train_set, n):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for edge in train_set:\n",
    "        u = int(edge[0])\n",
    "        w = int(edge[1])\n",
    "        row.append(u)\n",
    "        col.append(w)\n",
    "        row.append(w)\n",
    "        col.append(u)\n",
    "        data.append(1)\n",
    "        data.append(1)\n",
    "    return coo_matrix((data, (row, col)), shape=(n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_train(dataset_name):\n",
    "    max_id = 0\n",
    "    file_name = dataset_name + \"/train.in\"\n",
    "    fin_train = open(file_name, 'r')\n",
    "    edges = set()\n",
    "    nodes = set()\n",
    "    for line in fin_train:\n",
    "        line = line.strip()\n",
    "        u, w = line.split()\n",
    "        max_id = max(max_id, int(u))\n",
    "        max_id = max(max_id, int(w))\n",
    "        edges.add((u,w))\n",
    "        nodes.add(u)\n",
    "        nodes.add(w)\n",
    "    fin_train.close()\n",
    "    \n",
    "    return edges, nodes, max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sets(nodes, edges, division=10):\n",
    "    nodes_size = len(nodes)\n",
    "    edges_size = len(edges)\n",
    "    print \"Nodes size: \" + str(nodes_size)\n",
    "    print \"Edges size: \" + str(edges_size)\n",
    "    test_size = int(edges_size / division)\n",
    "    pos_edges = random.sample(edges, test_size)\n",
    "    pos_edges = set(pos_edges)\n",
    "\n",
    "    neg_edges = set()\n",
    "    while len(neg_edges) < test_size:\n",
    "        u = random.sample(nodes, 1)[0]\n",
    "        w = random.sample(nodes, 1)[0]\n",
    "        edge = (str(u),str(w))\n",
    "        if edge not in edges and u != w:\n",
    "            neg_edges.add(edge)\n",
    "        \n",
    "    edges_not_full = edges - pos_edges\n",
    "    \n",
    "    return pos_edges, neg_edges, edges_not_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_graph(dataset_name, dimension, nodes, edges_not_full):\n",
    "    graph = gv.Graph(format=\"dot\")\n",
    "    graph.engine = 'sfdp'\n",
    "    graph.graph_attr['dim'] = str(dimension)\n",
    "    graph.graph_attr['dimen'] = str(dimension)\n",
    "    graph = add_nodes(graph, nodes)\n",
    "    graph = add_edges(graph, edges_not_full)\n",
    "    file_name = dataset_name + \"/graph\" + str(dimension)\n",
    "    graph.render(file_name, view=False)\n",
    "    \n",
    "    graph.format = \"png\"\n",
    "    graph.render(file_name, view=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_edges_dot(dataset_name, dimension):\n",
    "    file_name = dataset_name + \"/graph\" + str(dimension) + \".dot\"\n",
    "    dot_graph = pydot.graph_from_dot_file(file_name)[0]\n",
    "    dot_nodes = dot_graph.get_nodes()\n",
    "    nodes_pos = {}\n",
    "    for node in dot_nodes:\n",
    "        name = node.get_name()\n",
    "        if name != 'node' and name != 'graph':\n",
    "            pos_str = node.get('pos').strip('\"')        \n",
    "            nodes_pos[name] = map(float, pos_str.split(','))\n",
    "    return nodes_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_sfdp(nodes_pos, pos_edges, neg_edges):\n",
    "    X, Y = make_dataset(nodes_pos, pos_edges, neg_edges, [dist])\n",
    "    clf = RF()\n",
    "    scores = cross_val_score(clf, X, Y, cv=10, scoring='roc_auc')\n",
    "    print(\"ROC AUC SFDP: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_nmf(edges, nodes_pos, pos_edges, neg_edges, n_components, max_id):\n",
    "    G = make_sparse_matrix(edges, max_id + 1)\n",
    "    model = NMF(n_components=n_components, init='random')\n",
    "    A = model.fit_transform(G)\n",
    "\n",
    "    X, Y = make_dataset(nodes_pos, pos_edges, neg_edges, [mf_score], A)\n",
    "    clf = RF()\n",
    "    scores = cross_val_score(clf, X, Y, cv=10, scoring='roc_auc')\n",
    "    print(\"ROC AUC NMF: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_svd(edges, nodes_pos, pos_edges, neg_edges, n_components, max_id):\n",
    "    G = make_sparse_matrix(edges, max_id + 1)\n",
    "    model = TruncatedSVD(n_components=n_components, algorithm='arpack')\n",
    "    A = model.fit_transform(G)\n",
    "\n",
    "    X, Y = make_dataset(nodes_pos, pos_edges, neg_edges, [mf_score], A)\n",
    "    clf = RF()\n",
    "    scores = cross_val_score(clf, X, Y, cv=10, scoring='roc_auc')\n",
    "    print(\"ROC AUC SVD: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_alg(data):\n",
    "    X = np.array(data)\n",
    "    pca = PCA()\n",
    "    pca.fit(X)\n",
    "    PCA(copy=True, iterated_power='auto', n_components='mle', random_state=None,\n",
    "      svd_solver='auto', tol=0.0, whiten=False)\n",
    "    print(pca.explained_variance_ratio_) \n",
    "    \n",
    "    pca = PCA('mle')\n",
    "    pca.fit(X)\n",
    "    PCA(copy=True, iterated_power='auto', n_components='mle', random_state=None,\n",
    "      svd_solver='full', tol=0.0, whiten=False)\n",
    "    print(pca.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mean(dim, nodes_pos):\n",
    "    values = []\n",
    "\n",
    "    for i in range(dim):\n",
    "        values.append([])\n",
    "\n",
    "    for node in nodes_pos:\n",
    "        for i in range(dim):\n",
    "            values[i].append(nodes_pos[node][i])\n",
    "        \n",
    "    for i in range(dim):\n",
    "        print np.mean(values[i])\n",
    "        print np.std(values[i])\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_graph(dataset_name, nodes_pos, edges):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    zs = []\n",
    "\n",
    "    for node in nodes_pos:\n",
    "        xs.append(nodes_pos[node][0])\n",
    "        ys.append(nodes_pos[node][1])\n",
    "        zs.append(nodes_pos[node][2])\n",
    "    \n",
    "#    print xs\n",
    "#    print ys\n",
    "#    print zs\n",
    "    \n",
    "#    print max(xs)\n",
    "#    print min(xs)\n",
    "    \n",
    "#    print max(ys)\n",
    "#    print min(ys)\n",
    "    \n",
    "#    print max(zs)\n",
    "#    print min(zs)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.scatter(xs, ys, zs, s=2.0, c='b', marker='o')\n",
    "\n",
    "    for edge in edges:\n",
    "        u = edge[0]\n",
    "        w = edge[1]\n",
    "        ax.plot([nodes_pos[u][0], nodes_pos[w][0]], [nodes_pos[u][1], nodes_pos[w][1]],zs=[nodes_pos[u][2], nodes_pos[w][2]], linewidth=1.0)\n",
    "\n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Y Label')\n",
    "    ax.set_zlabel('Z Label')\n",
    "\n",
    "    file_name = dataset_name + \"/3d.png\"\n",
    "    #plt.show()\n",
    "    fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_exp(dataset_name, dimension, n_components, division):\n",
    "    print \"Read train\"\n",
    "    edges, nodes, max_id = read_train(dataset_name)\n",
    "    \n",
    "    print \"Get sets\"\n",
    "    pos_edges, neg_edges, edges_not_full = get_sets(nodes, edges, division)\n",
    "    \n",
    "    print \"Render graph\"\n",
    "    print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "    render_graph(dataset_name, dimension, nodes, edges_not_full)\n",
    "    \n",
    "    print \"Read edges\"\n",
    "    print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "    nodes_pos = read_edges_dot(dataset_name, dimension)\n",
    "    \n",
    "    print \"Compute mean and std\"\n",
    "    compute_mean(dimension, nodes_pos)\n",
    "    \n",
    "    if dimension == 3:\n",
    "        print \"Draw graph\"\n",
    "        draw_graph(dataset_name, nodes_pos, edges)\n",
    "    \n",
    "    print \"SFDP\"\n",
    "    print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "    auc_sfdp(nodes_pos, pos_edges, neg_edges)\n",
    "    \n",
    "    print \"NMF\"\n",
    "    print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "    auc_nmf(edges, nodes_pos, pos_edges, neg_edges, n_components, max_id)\n",
    "    \n",
    "    print \"SVD\"\n",
    "    print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "    auc_svd(edges, nodes_pos, pos_edges, neg_edges, n_components, max_id)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dim_exp(dataset_name, num_exps, dimensions, n_components_nmf, n_components_svd):\n",
    "    dim_scores_sfdp = {}\n",
    "    dim_scores_nmf = {}\n",
    "    dim_scores_svd = {}\n",
    "    for dimension in dimensions:\n",
    "            dim_scores_sfdp[dimension] = np.array([])\n",
    "            dim_scores_nmf[dimension] = np.array([])\n",
    "            dim_scores_svd[dimension] = np.array([])\n",
    "            \n",
    "    edges, nodes, max_id = read_train(dataset_name)\n",
    "    \n",
    "    for i in range(num_exps):\n",
    "        print \"Launch \" + str(i)\n",
    "        print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "            \n",
    "        pos_edges, neg_edges, edges_not_full = get_sets(nodes, edges)\n",
    "    \n",
    "        for dimension in dimensions:\n",
    "            print \"Dimension \" + str(dimension)\n",
    "            render_graph(dataset_name, dimension, nodes, edges_not_full)\n",
    "            nodes_pos = read_edges_dot(dataset_name, dimension)\n",
    "                        \n",
    "            if dimension == 3:\n",
    "                print \"Draw graph\"\n",
    "                draw_graph(dataset_name, nodes_pos, edges)\n",
    "            \n",
    "            print \"PCA\" \n",
    "            data_for_pca = nodes_pos.values()\n",
    "            pca_alg(data_for_pca)\n",
    "\n",
    "            \n",
    "            print \"SFDP\"\n",
    "            sfdp_scores = auc_sfdp(nodes_pos, pos_edges, neg_edges)\n",
    "            dim_scores_sfdp[dimension] = np.append(dim_scores_sfdp[dimension], sfdp_scores)\n",
    "    \n",
    "            print \"NMF\"\n",
    "            nmf_scores = auc_nmf(edges, nodes_pos, pos_edges, neg_edges, n_components_nmf, max_id)\n",
    "            dim_scores_nmf[dimension] = np.append(dim_scores_nmf[dimension], nmf_scores)\n",
    "    \n",
    "            print \"SVD\"\n",
    "            svd_scores = auc_svd(edges, nodes_pos, pos_edges, neg_edges, n_components_svd, max_id)\n",
    "            dim_scores_svd[dimension] = np.append(dim_scores_svd[dimension], svd_scores)\n",
    "    \n",
    "    return dim_scores_sfdp, dim_scores_nmf, dim_scores_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_scores(dataset_name, dimensions, dim_scores_sfdp, dim_scores_nmf, dim_scores_svd):\n",
    "    for dim in dimensions:\n",
    "        dim_scores_sfdp[dim] = dim_scores_sfdp[dim].mean()\n",
    "        dim_scores_nmf[dim] = dim_scores_nmf[dim].mean()\n",
    "        dim_scores_svd[dim] = dim_scores_svd[dim].mean()\n",
    "    \n",
    "    print dim_scores_sfdp        \n",
    "        \n",
    "    scores_sfdp = []\n",
    "    scores_nmf = []\n",
    "    scores_svd = []\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        scores_sfdp.append(dim_scores_sfdp[dim])\n",
    "        scores_nmf.append(dim_scores_nmf[dim])\n",
    "        scores_svd.append(dim_scores_svd[dim])\n",
    "    \n",
    "    fig, ax = plt.subplots( nrows=1, ncols=1 )\n",
    "    ax.plot(dimensions, scores_sfdp, label='sfdp')\n",
    "    ax.plot(dimensions, scores_nmf, label='nmf')\n",
    "    ax.plot(dimensions, scores_svd, label='svd')\n",
    "    ax.legend()\n",
    "    file_name = dataset_name + \"/dimensions.png\"\n",
    "    fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.581009    0.41722784  0.00176316]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([(1, 2, 0), [2, 1, 0], [8, 4, 1], [2, -1, 0], [4, 4, 0], [1, 7, 0]])\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "PCA(copy=True, iterated_power='auto', n_components='mle', random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)\n",
    "print(pca.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sphere\n",
      "Launch 0\n",
      "2017-04-21 08:29:32\n",
      "Nodes size: 2798\n",
      "Edges size: 36186\n",
      "Dimension 2\n",
      "PCA\n",
      "[ 0.58244733  0.41755267]\n",
      "[ 0.58244733]\n",
      "SFDP\n",
      "ROC AUC SFDP: 0.84 (+/- 0.03)\n",
      "NMF\n",
      "ROC AUC NMF: 0.79 (+/- 0.03)\n",
      "SVD\n",
      "ROC AUC SVD: 0.94 (+/- 0.02)\n",
      "Dimension 3\n",
      "Draw graph\n",
      "PCA\n",
      "[ 0.48366169  0.38688427  0.12945404]\n",
      "[ 0.48366169  0.38688427]\n",
      "SFDP\n",
      "ROC AUC SFDP: 0.87 (+/- 0.03)\n",
      "NMF\n",
      "ROC AUC NMF: 0.87 (+/- 0.02)\n",
      "SVD\n",
      "ROC AUC SVD: 0.94 (+/- 0.02)\n",
      "Dimension 4\n",
      "PCA\n",
      "[  9.91252871e-01   4.74421082e-03   3.88863684e-03   1.14280893e-04]\n",
      "[ 0.99125287  0.00474421  0.00388864]\n",
      "SFDP\n",
      "ROC AUC SFDP: 0.87 (+/- 0.02)\n",
      "NMF\n",
      "ROC AUC NMF: 0.73 (+/- 0.04)\n",
      "SVD\n",
      "ROC AUC SVD: 0.94 (+/- 0.02)\n",
      "Dimension 5\n",
      "PCA\n",
      "[  9.92589856e-01   3.93296666e-03   2.93359873e-03   4.17992265e-04\n",
      "   1.25586185e-04]\n",
      "[  9.92589856e-01   3.93296666e-03   2.93359873e-03   4.17992265e-04]\n",
      "SFDP\n",
      "ROC AUC SFDP: 0.87 (+/- 0.03)\n",
      "NMF\n",
      "ROC AUC NMF: 0.88 (+/- 0.03)\n",
      "SVD\n",
      "ROC AUC SVD: 0.94 (+/- 0.01)\n",
      "Dimension 10\n",
      "PCA\n",
      "[  9.94538275e-01   1.94979037e-03   1.83334496e-03   8.68663331e-04\n",
      "   4.60780156e-04   2.83430241e-04   4.61245894e-05   1.21775045e-05\n",
      "   3.76601633e-06   3.64739062e-06]\n",
      "[  9.94538275e-01   1.94979037e-03   1.83334496e-03   8.68663331e-04\n",
      "   4.60780156e-04   2.83430241e-04   4.61245894e-05   1.21775045e-05]\n",
      "SFDP\n",
      "ROC AUC SFDP: 0.87 (+/- 0.03)\n",
      "NMF\n",
      "ROC AUC NMF: 0.77 (+/- 0.03)\n",
      "SVD\n",
      "ROC AUC SVD: 0.94 (+/- 0.02)\n",
      "saving\n",
      "{10: 0.87363490362885299, 2: 0.83716780470308017, 3: 0.86991501671209337, 4: 0.87142873575776003, 5: 0.87072940683932676}\n"
     ]
    }
   ],
   "source": [
    "#dataset_names = [\"airport\", \"Ca-HelpTh\", \"chicago\", \"Conflict\", \"euroroad\", \"EuroSiS\", \"PowerGrid\"]\n",
    "#dimensions = [2, 3, 4, 5, 6, 7, 8 ,9, 10]\n",
    "\n",
    "dataset_names = [\"sphere\"]\n",
    "dimensions = [2, 3, 4, 5, 10]\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print dataset_name\n",
    "    dim_scores_sfdp, dim_scores_nmf, dim_scores_svd = run_dim_exp(dataset_name, 1, dimensions, 10, 30)\n",
    "    print \"saving\"\n",
    "    save_scores(dataset_name, dimensions, dim_scores_sfdp, dim_scores_nmf, dim_scores_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: airport\n",
      "Division: 5/%\n",
      "Dim: 2\n",
      "Components: 30\n",
      "\n",
      "Read train\n",
      "Get sets\n",
      "Nodes size: 1574\n",
      "Edges size: 28236\n",
      "Render graph\n",
      "2017-04-20 22:01:01\n",
      "Read edges\n",
      "2017-04-20 22:01:04\n"
     ]
    }
   ],
   "source": [
    "#dataset_names = [\"airport\", \"Ca-HelpTh\", \"chicago\", \"Conflict\", \"euroroad\", \"EuroSiS\", \"PowerGrid\"]\n",
    "#dimensions = [2, 3, 4, 10]\n",
    "dataset_names = [\"airport\", \"Ca-HelpTh\", \"PowerGrid\"]\n",
    "divisions = [5, 10, 15, 25, 35]\n",
    "dimensions = [2, 3]\n",
    "n_components = [30]\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for division in divisions:\n",
    "        for dimension in dimensions:\n",
    "            for component in n_components:\n",
    "                print \"Dataset: \" + dataset_name\n",
    "                print \"Division: \" + str(division) + \"/%\"\n",
    "                print \"Dim: \" + str(dimension)\n",
    "                print \"Components: \" + str(component)\n",
    "                print\n",
    "                run_exp(dataset_name, dimension, component, division)\n",
    "                print \"---------------------------\"\n",
    "                print\n",
    "                print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
